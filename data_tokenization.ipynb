{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efQmyY9iISRM",
        "outputId": "9786fdb7-a20f-443b-c0a5-268d1f63252b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting youtokentome\n",
            "  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.9/dist-packages (from youtokentome) (8.1.3)\n",
            "Building wheels for collected packages: youtokentome\n",
            "  Building wheel for youtokentome (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp39-cp39-linux_x86_64.whl size=1920747 sha256=c7ce0c9f51334cd7bcd74467e919d295975ac89fa7a92e3e8c61011b0a577d00\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/99/eb/b72f9c470f14438147d8aa1ff91f9f5191b5e5d825c4b0a12c\n",
            "Successfully built youtokentome\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install youtokentome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjpAb1GcHeBw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import youtokentome as yttm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkcOEtyxII1L",
        "outputId": "58859dc1-f845-45f5-d636-1a075c8e25c4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU0gqcwI2Qr8"
      },
      "outputs": [],
      "source": [
        "MAX_TITLE_LENGTH=20\n",
        "MAX_ABS_LENGTH=300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKZcEoUNh1UZ"
      },
      "source": [
        "Train the tokenizer with a vocabulary size of 30000 and the predefined indicies for special tokens shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRSQbpWqHjRj"
      },
      "outputs": [],
      "source": [
        "yttm.BPE.train(\"/content/gdrive/MyDrive/corpus.txt\", \"/content/gdrive/MyDrive/tokenizer\", 30000, 1.0, n_threads=-1, pad_id=0, unk_id=1, bos_id=2, eos_id=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agUxAhKsUllz",
        "outputId": "4c2d464f-f025-4463-ebf3-995013b602ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 30000\n"
          ]
        }
      ],
      "source": [
        "bpe = yttm.BPE(model=\"/content/gdrive/MyDrive/tokenizer\")\n",
        "print(f\"Vocabulary size: {bpe.vocab_size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po5ZWk5FbKTT"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/gdrive/MyDrive/corpus.txt\", \"r\") as re:\n",
        "  sent = re.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld-q5fz3jpDO"
      },
      "outputs": [],
      "source": [
        "encs = bpe.encode(sent, bos=True, eos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XsJZ9ZdmJUT"
      },
      "outputs": [],
      "source": [
        "\n",
        "count=0\n",
        "new_data = []\n",
        "\n",
        "while count < len(encs):\n",
        "  title_length = len(encs[count])\n",
        "  abstract_length = len(encs[count+1])\n",
        "  if (title_length > MAX_TITLE_LENGTH) or (abstract_length > MAX_ABS_LENGTH):\n",
        "    count += 2\n",
        "    continue\n",
        "  pad_title = encs[count] + [0 for _ in range(MAX_TITLE_LENGTH - title_length)]\n",
        "  pad_abstract = encs[count+1] + [0 for _ in range(MAX_ABS_LENGTH - abstract_length)]\n",
        "  new_data.append(np.array([np.array(pad_title), np.array(pad_abstract)]))\n",
        "  count += 2\n",
        "\n",
        "new_data = np.array(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVQETf0Jp-IV"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/data.pickle', 'wb+') as f:\n",
        "  pickle.dump(new_data, f, pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
